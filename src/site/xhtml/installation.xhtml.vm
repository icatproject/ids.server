<html>
<head>
<title>IDS Installation</title>
</head>
<body>



	<h1>Installation</h1>

	<h2>Compatibility</h2>
	<p>This will work with an ICAT version of 4.3.0 or greater and
		requires plugins implementing the IDS plugin interface 1.5.0.</p>

	<h2>Prerequisites</h2>

	<ul>
		<li>The ids distribution: <a
			href="${repoUrl}/org/icatproject/ids.server/${project.version}/ids.server-${project.version}-distro.zip">ids.server-${project.version}-distro.zip</a>
		</li>

		<li>A suitable deployed container to support a web application.
			Testing has been carried out with Payara41 and Glassfish 4.0.<a
			href="http://icatproject.org/installation/glassfish/">Glassfish
				(payara) installation instructions</a> are available.
		</li>

		<li>A deployed plugin or plugins for the storage mechanism you
			wish to use. Please see <a href="/site/ids/plugin">plugin</a> to see
			the interface you must implement. You might also like to look at the
			<a href="/site/ids/storage_file">file storage plugin</a> as an
			example.
		</li>

		<li>Python (version 2.4 to 2.7) installed on the server.</li>
	</ul>

	<h2>Summary of steps</h2>


	<ol>
		<li>Please follow <a
			href="http://icatproject.org/installation/component/"> the
				generic installation instructions</a>
		</li>

		<li>Check that it works.</li>
	</ol>

	<h2>The setup.properties file</h2>

	<dl>
		<dt>container</dt>
		<dd>
			Values must be chosen from: <a target="_blank"
				href="http://www.eclipse.org/eclipselink/api/2.6/org/eclipse/persistence/config/TargetServer.html">TargetServer</a>
			Though only Glassfish is working properly at the moment.
		</dd>
		<dt>home</dt>
		<dd>is the top level of the container installation. For
			glasssfish it must contain "glassfish/domains" and for wildfly it
			must contain jboss-modules.jar.</dd>
		<dt>port</dt>
		<dd>is the administration port of the container which is
			typically 4848 for glassfish and 9990 for wildfly.</dd>
		<dt>secure</dt>
		<dd>must be set to true or false. If true then only https and not
			http connections will be allowed.</dd>
	</dl>

	<h2>The run.properties file</h2>

	All the property values are passed to the plugin(s). A plugin is only
	expected to look at properties defined for its use. It is recommended
	that such properties have names starting
	<code>plugin.main.</code>
	or
	<code>plugin.archive</code>
	. to make sure that they don't clash with any current or future
	run.properties of the ids.server. To find the names of these properties
	please consult the documentation for your plugin(s).

	<h3>General Properties</h3>

	<dl>
		<dt>icat.url</dt>
		<dd>
			The url of the machine hosting the icat service. It should normally
			just have the scheme, the hostname and the port. For example:
			<code>https://example.com:443</code>
		</dd>

		<dt>plugin.zipMapper.class</dt>
		<dd>The class name of the ZipMapper which defines the Zip file
			structure you want. The class must be deployed in the lib/applibs
			directory of your domain and must be packaged with all it
			dependencies.</dd>

		<dt>plugin.main.class</dt>
		<dd>The class name of the main storage plugin. The class must be
			deployed in the lib/applibs directory of your domain and must be
			packaged with all it dependencies.</dd>

		<dt>cache.dir</dt>
		<dd>The location (absolute or relative to the config directory of
			the domain) of a directory where the working files for the IDS 
			are held eg. prepared, completed and failed files.</dd>

		<dt>preparedCount</dt>
		<dd>The number of preparedId values from prepareData calls to
			remember.</dd>

		<dt>processQueueIntervalSeconds</dt>
		<dd>The frequency of checking the process queue. This is used
			both for cleaning old information from memory and for triggering
			movements between main and archive storage (if selected).</dd>

		<dt>rootUserNames</dt>
		<dd>A space separated list of users allowed to make the
			getServiceStatus call. The user name must include the mechanism if
			the authenticators have been configured that way.</dd>

		<dt>sizeCheckIntervalSeconds</dt>
		<dd>How frequently to check the cache sizes and clean up if
			necessary.</dd>

		<dt>readOnly</dt>
		<dd>If true disables write operations (put and delete).</dd>

		<dt>linkLifetimeSeconds</dt>
		<dd>The length of time in seconds to keep the links established
			by the getLink call. If this is set to zero then the getLink call
			will return a NotImplementedException.</dd>

		<dt>reader</dt>
		<dd>
			Space separated icat plugin name and credentials for a user permitted
			to read all datasets, datafiles, investigations and facilities. For
			example:
			<code>db username root password secret.</code>
		</dd>

		<dt>key</dt>
		<dd>Optional key value. If specified this contributes to the
			computation of a cryptographic hash added to the location value in
			the database. The ids plugins do not see the hash. The key must of
			course be long enough to be secure and must be kept private.</dd>

		<dt>maxIdsInQuery</dt>
		<dd>The number of literal id values to be generated in an ICAT
			query. For Oracle this must not exceed 1000.</dd>

		<dt>missingFilesZipEntryName</dt>
		<dd>Optional. Specifies the filename (and path if required) of a file
			which will be added to the download zip file if there are files 
			which failded to restore for a request. If not specified, the 
			default of MISSING_FILES.txt will be used with the file appearing 
			in the root of the zip file. The file can also be put in a 
			subfolder using eg. path/to/FILENAME.txt </dd>
			
		<dt>log.list</dt>
		<dd>Optional. If present it specifies a set of call types to log
			via JMS calls. The types are specified by a space separated list of
			values taken from READ, WRITE, LINK, MIGRATE, PREPARE and INFO.</dd>

		<dt>jms.topicConnectionFactory</dt>
		<dd>Optional. If present it overrides the default JMS connection
			factory.</dd>

		<dt>logback.xml</dt>
		<dd>This is optional. If present it must specify the path to a
			logback.xml file. The path may be absolute or relative to the config
			directory. The file ids.logback.xml.example may be renamed to
			ids.logback.xml to get started.</dd>

		<dt>useReaderForPerformance</dt>
		<dd>Optional. If true allows the IDS to make use of the reader account
			to improve query performance. Note that this bypasses some
			access permission checks. It essentially has the effect of
			allowing any user access to datafiles if that user has access
			permission to the dataset the datafiles belong to. This is
			similar to an implicit PublicStep from Dataset to Datafile.  Do
			not set this flag unless you would be happy to also create this
			PublicStep in your ICAT!</dd>

	</dl>

	<h3>Properties for archive storage</h3>
	<p>If you are not using archive storage then all of these
		properties should be omitted.</p>
	<dl>

		<dt>plugin.archive.class</dt>
		<dd>The class name of the archive storage plugin. The class must
			be deployed in the lib/applibs directory of your domain and must be
			packaged with all it dependencies.</dd>

		<dt>delayDatasetWritesSeconds</dt>
		<dd>The amount of time to wait before writing a dataset archive storage.
			This exists to allow enough time for all the datafiles to be added to
			a dataset before it is zipped and written.  This property is only
			used if storageUnit is set to dataset, see below.</dd>

		<dt>delayDatafileOperationsSeconds</dt>
		<dd>The amount of time to wait before processing any deferred operations for
			datafiles.  Operations are collected during this period of time and
			processed at once in combined threads.  This property is only
			used if storageUnit is set to datafile, see below.</dd>

		<dt>startArchivingLevel1024bytes</dt>
		<dd>If the space used in main storage exceeds this then datasets
			will be archived (oldest first) until the space used is below
			stopArchivingLevel1024bytes.</dd>

		<dt>stopArchivingLevel1024bytes</dt>
		<dd>See startArchivingLevel1024bytes.</dd>

		<dt>storageUnit</dt>
		<dd>May be dataset or datafile and is not case sensitive. A value
			of "dataset" means that a whole dataset of files are zipped up to be
			stored as a single file whereas "datafile" causes datafiles to be
			stored individually.</dd>

		<dt>tidyBlockSize</dt>
		<dd>The number of datafiles or datasets to get back in one call
			for archive request when space on main storage is low.</dd>

		<dt>maxRestoresPerThread</dt>
		<dd>The maximum number of files that should be requested from Archive
			Storage in one go. Requests that exceed this limit will be split up
			into multiple smaller requests that are below this threshold.</dd>

		<dt>enableWrite</dt>
		<dd>Optional. If true, the write call will be enabled, if false, it will be
			disabled. If not set, the readOnly flag will take control and the
			write call will be disabled if readOnly is true and enabled if
			not.</dd>

	</dl>


	<h3>Properties for file checking</h3>
	<p>When a datafile is added to the IDS its length and checksum are
		computed and stored in ICAT. File checking, if enabled, cycles through
		all the stored data making sure that they can be read and that files
		have the expected size and checksum.</p>
	<dl>
		<dt>filesCheck.parallelCount</dt>
		<dd>
			This must always be set, and if non zero then the readability of the
			data will be checked. The behaviour is dependent upon whether or not
			archive storage has a been requested. In the case of single level
			storage this is done in groups of files where the group size is
			defined by this parameter. If archive storage has been requested then
			only the archive is checked. Each file in the archive holds a
			complete dataset and this filesCheck.parallelCount parameter then
			defines how many dataset files will be checked in parallel.
			<p>In the case of checking datasets in the archive storage these
				are unzipped on the fly to compute the checksum of each file inside
				the zip file as well as its length.</p>
			<p>If the archive storage has a long latency then it is useful to
				have a "large" value, however a thread is started for each stored
				file so the value of this parameter should not be too large.</p>
		</dd>
		<dt>filesCheck.gapSeconds</dt>
		<dd>the number of seconds to wait before launching a check of the
			next batch of datafiles or datasets.</dd>
		<dt>filesCheck.lastIdFile</dt>
		<dd>the location of a file which is used to store the id value of
			the last datafile or dataset to be checked. This is so that if the
			IDS is restarted it will continue checking where it left off. If this
			file is deleted the ids will restart checking from the beginning. The
			parameters filesCheck.parallelCount and filesCheck.gapSeconds should
			be set so that the data are all checked with the desired frequency
			but without excessive I/O. A nagios plugin might check that this file
			is being written periodically and that its contents change.</dd>
		<dt>filesCheck.errorLog</dt>
		<dd>the file with a list of errors found. The file is not kept
			open but instead is opened in append mode each time a problem is
			spotted and then closed. A nagios plugin might be set up to watch
			this file. Entries in the file are data stamped and new entries are
			simply appended without regard for the existence of an entry for the
			same file.</dd>
	</dl>

	<h2>Check that the ids server works</h2>
	<p>
		Enter a url of the form
		<code>https://example.com:443/ids/ping</code>
		into a web browse and it should respond:
		<code>IdsOK</code>
		. Note the url is that of the machine hosting the IDS followed by
		"/ids/ping"
	</p>

</body>
</html>

